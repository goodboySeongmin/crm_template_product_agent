import json
import pandas as pd
import numpy as np
from sqlalchemy import create_engine, text
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer

# 1. DB ì ‘ì† ì •ë³´
db_host = "127.0.0.1"
db_port = "3307"
db_user = "root"
db_pass = "goodboyseongmin12!"
db_name = "crm"

# í…Œì´ë¸” ì •ë³´ (ëª¨ë“  ë¡œì§ì—ì„œ ì“°ëŠ” í…Œì´ë¸” í†µí•© ì •ì˜)
user_table = "users"
feature_table = "user_features"
product_table = "products"
map_table = "product_concern_map"
ocr_table = "product_ocr_text"
cart_table = "carts"
cart_item_table = "cart_items"
order_table = "orders"
order_item_table = "order_items"

# DB ì—°ê²°
db_url = f"mysql+pymysql://{db_user}:{db_pass}@{db_host}:{db_port}/{db_name}"
engine = create_engine(db_url)

# ëª¨ë¸ ë¡œë“œ (ìµœì´ˆ 1íšŒ ì‹¤í–‰)
print("â³ AI ëª¨ë¸ ë¡œë”© ì¤‘...")
embedding_model = SentenceTransformer('jhgan/ko-sroberta-multitask')
print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# =========================================================
# [Case 1] counseling: AI ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ
# =========================================================
def process_ai_recommendation(run_id=None):
    print(f"ğŸ“¡ [Case 1] AI ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ ë¡œì§ ì‹¤í–‰ (Run ID: {run_id})")
    
    if not run_id: return None

    # 1. ë°ì´í„° ì¡°íšŒ
    query_target = f"SELECT payload_json FROM handoffs WHERE stage = 'TARGET_AUDIENCE' AND run_id = '{run_id}' LIMIT 1"
    query_template = f"SELECT payload_json FROM handoffs WHERE stage = 'SELECTED_TEMPLATE' AND run_id = '{run_id}' LIMIT 1"

    try:
        df_target = pd.read_sql(query_target, engine)
        df_template = pd.read_sql(query_template, engine)
    except Exception as e:
        print(f"âŒ DB ì ‘ì† ì‹¤íŒ¨: {e}")
        return None

    if df_target.empty or df_template.empty: return None

    target_data = json.loads(df_target.iloc[0]['payload_json'])
    template_data = json.loads(df_template.iloc[0]['payload_json'])
    user_ids = target_data.get('user_ids', [])
    template_body = template_data.get('body_with_slots', "")

    if not user_ids: return None

    # 2. í‚¤ì›Œë“œ ì¶”ì¶œ
    try:
        campaign_keywords_list = template_data['notes']['campaign_text_normalized']['keywords']
        campaign_text = " ".join(campaign_keywords_list)
        print(f"ğŸ¯ [ìº í˜ì¸ í‚¤ì›Œë“œ]: {campaign_text}")
    except KeyError:
        campaign_text = "ì¶”ì²œ ìƒí’ˆ"

    # 3. ì¹´í…Œê³ ë¦¬ ì„ ì •
    ids_tuple = tuple(user_ids)
    in_clause = f"('{user_ids[0]}')" if len(user_ids) == 1 else str(ids_tuple)

    user_query = f"SELECT f.keyword FROM {user_table} u LEFT JOIN {feature_table} f ON u.user_id = f.user_id WHERE u.user_id IN {in_clause}"
    user_df = pd.read_sql(user_query, engine)
    valid_keywords = user_df['keyword'].dropna()
    
    if valid_keywords.empty: return None
    winning_category = valid_keywords.value_counts().idxmax().split(',')[0].strip()
    print(f"ğŸ† [1ì°¨ í•„í„°] ì¹´í…Œê³ ë¦¬: '{winning_category}'")

    # 4. ìƒí’ˆ ì¡°íšŒ
    product_query = f"""
        SELECT p.prod_sn, p.product_name, p.detail_url, o.keyword as db_product_keywords, o.detail_slot
        FROM {product_table} p
        JOIN {map_table} m ON p.prod_sn = m.prod_sn
        LEFT JOIN {ocr_table} o ON p.prod_sn = o.prod_sn
        WHERE m.product_concern = '{winning_category}'
    """
    candidate_df = pd.read_sql(product_query, engine)
    if candidate_df.empty: return None

    candidate_df['db_product_keywords'] = candidate_df['db_product_keywords'].fillna("").astype(str)
    candidate_df['detail_url'] = candidate_df['detail_url'].fillna("")
    candidate_df['detail_slot'] = candidate_df['detail_slot'].fillna("")
    candidate_df['offer'] = ""

    # 5. AI ë§¤ì¹­
    campaign_embedding = embedding_model.encode([campaign_text])
    product_embeddings = embedding_model.encode(candidate_df['db_product_keywords'].tolist())
    similarity_scores = cosine_similarity(campaign_embedding, product_embeddings).flatten()
    
    best_match_idx = similarity_scores.argmax()
    final_product = candidate_df.iloc[best_match_idx]
    print(f"ğŸ‘‰ [ì„ ì •]: {final_product['product_name']} (ìœ ì‚¬ë„: {similarity_scores[best_match_idx]:.4f})")

    # 6. ë©”ì‹œì§€ ìƒì„±
    final_results = []
    user_name_df = pd.read_sql(f"SELECT user_id, customer_name FROM {user_table} WHERE user_id IN {in_clause}", engine)
    name_map = user_name_df.set_index('user_id')['customer_name'].to_dict()

    print("\n[AI ë©”ì‹œì§€ ë¯¸ë¦¬ë³´ê¸°]")
    for uid in user_ids:
        real_name = name_map.get(uid, "ê³ ê°")
        slot_values = {
            "customer_name": real_name, "product_name": final_product['product_name'],
            "offer": final_product['offer'], "cta": final_product['detail_url'], "product_detail": final_product['detail_slot']
        }
        try:
            completed_message = template_body.format(**slot_values)
            print(f"[{uid}] {completed_message}")
            final_results.append({
                "run_id": run_id, "user_id": uid, "customer_name": real_name, "phone_number": "010-0000-0000",
                "message": completed_message, "product_id": final_product['prod_sn'], "status": "READY"
            })
        except KeyError: pass

    return final_results


# =========================================================
# [Case 2] cart: ì¥ë°”êµ¬ë‹ˆ ì´íƒˆ (ì˜¤ë˜ëœ ìˆœ)
# =========================================================
def process_abandoned_cart(run_id=None):
    print(f"ğŸ“¡ [Case 2] ì¥ë°”êµ¬ë‹ˆ ì´íƒˆ ë¡œì§ ì‹¤í–‰ (Run ID: {run_id})")

    if not run_id: return None

    # 1. ë°ì´í„° ì¡°íšŒ
    query_target = f"SELECT payload_json FROM handoffs WHERE stage = 'TARGET_AUDIENCE' AND run_id = '{run_id}' LIMIT 1"
    query_template = f"SELECT payload_json FROM handoffs WHERE stage = 'SELECTED_TEMPLATE' AND run_id = '{run_id}' LIMIT 1"

    try:
        df_target = pd.read_sql(query_target, engine)
        df_template = pd.read_sql(query_template, engine)
    except Exception as e:
        print(f"âŒ DB ì ‘ì† ì‹¤íŒ¨: {e}")
        return None

    if df_target.empty or df_template.empty: return None

    target_data = json.loads(df_target.iloc[0]['payload_json'])
    template_data = json.loads(df_template.iloc[0]['payload_json'])
    user_ids = target_data.get('user_ids', [])
    template_body = template_data.get('body_with_slots', "")
    
    if not user_ids: return None

    # 2. ìœ ì €ë³„ ì¥ë°”êµ¬ë‹ˆ ì¡°íšŒ (ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ)
    ids_tuple = tuple(user_ids)
    in_clause = f"('{user_ids[0]}')" if len(user_ids) == 1 else str(ids_tuple)

    personal_query = f"""
        SELECT u.user_id, u.customer_name, p.prod_sn, p.product_name, p.detail_url, o.detail_slot, c.created_at
        FROM {cart_table} c
        JOIN {user_table} u ON c.user_id = u.user_id
        JOIN {cart_item_table} ci ON c.cart_id = ci.cart_id
        JOIN {product_table} p ON ci.prod_sn = p.prod_sn
        LEFT JOIN {ocr_table} o ON p.prod_sn = o.prod_sn
        WHERE c.status = 'ABANDONED' AND c.user_id IN {in_clause}
    """
    
    df = pd.read_sql(personal_query, engine)
    if df.empty:
        print("â›” ì¥ë°”êµ¬ë‹ˆ ì´íƒˆ ë‚´ì—­ ì—†ìŒ")
        return None

    # 3. ì •ë ¬ ë° ì¤‘ë³µ ì œê±°
    df['created_at'] = pd.to_datetime(df['created_at'])
    df_sorted = df.sort_values(by=['user_id', 'created_at'], ascending=[True, True])
    target_df = df_sorted.drop_duplicates(subset=['user_id'], keep='first').copy()
    target_df.fillna("", inplace=True)
    target_df['offer'] = ""

    print(f"âœ… ëŒ€ìƒ ìœ ì €: {len(target_df)}ëª…")

    # 4. ë©”ì‹œì§€ ìƒì„±
    final_results = []
    print("\n[ì¥ë°”êµ¬ë‹ˆ ë©”ì‹œì§€ ë¯¸ë¦¬ë³´ê¸°]")
    for _, row in target_df.iterrows():
        uid = row['user_id']
        name = row['customer_name']
        slot_values = {
            "customer_name": name, "product_name": row['product_name'], "offer": row['offer'],
            "cta": row['detail_url'], "product_detail": row['detail_slot']
        }
        try:
            completed_message = template_body.format(**slot_values)
            print(f"[{uid}] {completed_message}")
            final_results.append({
                "run_id": run_id, "user_id": uid, "customer_name": name, "phone_number": "010-0000-0000",
                "message": completed_message, "product_id": row['prod_sn'], "status": "READY"
            })
        except KeyError: pass

    return final_results


# =========================================================
# [Case 3] repurchase: ì¬êµ¬ë§¤ ìœ ë„ (ìµœë‹¤ êµ¬ë§¤ ìƒí’ˆ) - [NEW]
# =========================================================
def process_repurchase_recommendation(run_id=None):
    print(f"ğŸ“¡ [Case 3] ìœ ì €ë³„ ìµœë‹¤ êµ¬ë§¤(ì¬êµ¬ë§¤) ìƒí’ˆ ë¶„ì„ ì‹œì‘ (Run ID: {run_id})")

    if not run_id: return None

    # 1. ë°ì´í„° ì¡°íšŒ
    query_target = f"SELECT payload_json FROM handoffs WHERE stage = 'TARGET_AUDIENCE' AND run_id = '{run_id}' LIMIT 1"
    query_template = f"SELECT payload_json FROM handoffs WHERE stage = 'SELECTED_TEMPLATE' AND run_id = '{run_id}' LIMIT 1"

    try:
        df_target = pd.read_sql(query_target, engine)
        df_template = pd.read_sql(query_template, engine)
    except Exception as e:
        print(f"âŒ DB ì ‘ì† ì‹¤íŒ¨: {e}")
        return None

    if df_target.empty or df_template.empty: return None

    target_data = json.loads(df_target.iloc[0]['payload_json'])
    template_data = json.loads(df_template.iloc[0]['payload_json'])
    user_ids = target_data.get('user_ids', [])
    template_body = template_data.get('body_with_slots', "")
    
    if not user_ids: return None

    # 2. ìœ ì €ë³„ êµ¬ë§¤ ì´ë ¥ ì¡°íšŒ (DELIVERED ìƒíƒœ)
    ids_tuple = tuple(user_ids)
    in_clause = f"('{user_ids[0]}')" if len(user_ids) == 1 else str(ids_tuple)

    history_query = f"""
        SELECT o.user_id, u.customer_name, oi.prod_sn, p.product_name, p.detail_url as cta, ocr.detail_slot as product_detail
        FROM {order_table} o
        JOIN {user_table} u ON o.user_id = u.user_id
        JOIN {order_item_table} oi ON o.order_id = oi.order_id
        JOIN {product_table} p ON oi.prod_sn = p.prod_sn
        LEFT JOIN {ocr_table} ocr ON p.prod_sn = ocr.prod_sn
        WHERE o.order_status = 'DELIVERED' AND o.user_id IN {in_clause}
    """
    
    df_history = pd.read_sql(history_query, engine)
    if df_history.empty:
        print("â›” êµ¬ë§¤ ì´ë ¥ ì—†ìŒ")
        return None

    df_history['cta'] = df_history['cta'].fillna("")
    df_history['product_detail'] = df_history['product_detail'].fillna("")
    df_history['offer'] = ""

    # 3. ìµœë‹¤ êµ¬ë§¤ ìƒí’ˆ ì„ ì • (Frequency ê³„ì‚°)
    df_count = df_history.groupby(['user_id', 'prod_sn']).size().reset_index(name='purchase_count')
    df_product_info = df_history[['prod_sn', 'product_name', 'cta', 'product_detail', 'offer']].drop_duplicates()
    df_merged = pd.merge(df_count, df_product_info, on='prod_sn', how='left')
    df_user_info = df_history[['user_id', 'customer_name']].drop_duplicates()
    df_merged = pd.merge(df_merged, df_user_info, on='user_id', how='left')

    # ì •ë ¬: [ìœ ì €ID] ì˜¤ë¦„ì°¨ìˆœ, [êµ¬ë§¤íšŸìˆ˜] ë‚´ë¦¼ì°¨ìˆœ -> ìœ ì €ë³„ 1ìœ„ ìƒí’ˆ ì„ ì •
    df_sorted = df_merged.sort_values(by=['user_id', 'purchase_count'], ascending=[True, False])
    final_df = df_sorted.drop_duplicates(subset=['user_id'], keep='first')

    print(f"âœ… ëŒ€ìƒ ìœ ì €: {len(final_df)}ëª… (ì¬êµ¬ë§¤ ì¶”ì²œ)")

    # 4. ë©”ì‹œì§€ ìƒì„±
    final_results = []
    print("\n[ì¬êµ¬ë§¤ ë©”ì‹œì§€ ë¯¸ë¦¬ë³´ê¸°]")
    for _, row in final_df.iterrows():
        uid = row['user_id']
        name = row['customer_name']
        cnt = row['purchase_count']
        
        slot_values = {
            "customer_name": name, "product_name": row['product_name'], "offer": row['offer'],
            "cta": row['cta'], "product_detail": row['product_detail']
        }
        try:
            completed_message = template_body.format(**slot_values)
            print(f"[{uid}] {completed_message}")
            print(f"   ğŸ‘‰ (ê³¼ê±° {cnt}íšŒ êµ¬ë§¤)")
            
            final_results.append({
                "run_id": run_id, "user_id": uid, "customer_name": name, "phone_number": "010-0000-0000",
                "message": completed_message, "product_id": row['prod_sn'], "status": "READY"
            })
        except KeyError: pass

    return final_results